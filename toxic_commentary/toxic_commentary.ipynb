{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проект для «Викишоп» с BERT, spaCy и TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
    "\n",
    "Обучите модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок.\n",
    "\n",
    "Постройте модель со значением метрики качества *F1* не меньше 0.75. \n",
    "\n",
    "**Инструкция по выполнению проекта**\n",
    "\n",
    "1. Загрузите и подготовьте данные.\n",
    "2. Обучите разные модели. \n",
    "3. Сделайте выводы.\n",
    "\n",
    "Для выполнения проекта применять *BERT* необязательно, но вы можете попробовать.\n",
    "\n",
    "**Описание данных**\n",
    "\n",
    "Данные находятся в файле `toxic_comments.csv`. Столбец *text* в нём содержит текст комментария, а *toxic* — целевой признак."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Импорт библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import re\n",
    "\n",
    "import time\n",
    "\n",
    "import spacy\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import torch\n",
    "\n",
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "nltk.download('wordnet') \n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "!pip install -U spacy\n",
    "!python -m spacy download en_core_web_md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Подготовка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159571 entries, 0 to 159570\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   text    159571 non-null  object\n",
      " 1   toxic   159571 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 2.4+ MB\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('toxic_comments.csv')\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напишем функцию для обработки текста."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_tokenize_lemmatize(text:str, stop_words:list=stopwords.words('english')) -> str:\n",
    "    ''' Приведение к нижнему регистру -> фильрация символов совмещенная с токенизацией, остаются только латинские буквы и апострофы ->\n",
    "    -> лемматизация -> в случае если на выход поступает пустая строка, она заменяется на '0'\n",
    "    \n",
    "    '''\n",
    "    clean_tokens = []\n",
    "    text = text.lower()\n",
    "    tokens = re.sub(r'[^A-Za-z\\']', ' ', text).split()\n",
    "    for token in tokens:\n",
    "        #if token not in stop_words:                                   # В списке стоп-слов нет некоторых стоп-слов в том виде в котором они приходят после лемматизации,\n",
    "        clean_tokens.append(WordNetLemmatizer().lemmatize(token))      # поэтому лучше от них избавляться на этап раньше\n",
    "    clean_string = ' '.join(clean_tokens)\n",
    "    if clean_string == '': clean_string = '0'\n",
    "    return clean_string                                   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "P.s. были созданы версии лемматизатора с и без очистки от стоп-слов, однако тот, что стоп-слова не трогал позволил в конечном итоге получить чуть лучший результат f1.\n",
    "\n",
    "И создадим новый столбец с лемматизированным и очищенным текстом."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 4s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data['lemmatized'] = data['text'].apply(clean_tokenize_lemmatize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучение будет проводится при помощи трех подходов:\n",
    "\n",
    "* С помощью TF-IDF\n",
    "* С помощью библиотеки spaCy\n",
    "* С помощью BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В каждом из подходов сгенерированные признаки будут поступать на вход следующему набору моделей:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_params = {\n",
    "    LogisticRegression(random_state=24) : dict(),\n",
    "    LGBMClassifier(random_state=24) : dict(max_depth=range(-1, 201), num_leaves=range(5, 101), n_estimators=range(1, 201)),\n",
    "    DummyClassifier() : dict(strategy=['most_frequent', 'prior', 'stratified', 'uniform', 'constant'])\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В отличие от других подходов TF-IDF будет более разумно обучать через Pipeline. Для того чтобы TF-IDF векторизатор настраивался только на тренировочной выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_models_params = {\n",
    "    LogisticRegression(random_state=24) : [{}],\n",
    "    LGBMClassifier(random_state=24) : [{'model__max_depth' : range(-1, 201), 'model__num_leaves' : range(5, 101), 'model__n_estimators' : range(1, 201)}],\n",
    "    DummyClassifier(strategy='uniform') : [{}]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далее следуют функции для обучения и подбора гиперпараметров(`model_training`) и для отображения результатов(`model_scoring`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def model_training(models_params, X, y, n_iter=10):\n",
    "    trained_models=[]\n",
    "    for model, params in models_params.items():\n",
    "        timer = time.time()\n",
    "        random_search = RandomizedSearchCV(model, \n",
    "                                           param_distributions=params, \n",
    "                                           scoring='f1', \n",
    "                                           random_state=24, \n",
    "                                           n_iter=n_iter, \n",
    "                                           cv=3, \n",
    "                                           verbose=True\n",
    "                                          )\n",
    "        random_search.fit(X, y)\n",
    "        timer = time.time() - timer\n",
    "        print(f'Обучение модели {model} заняло {timer:.2f} сек или {(timer / 60):.2f} мин')\n",
    "        print('---------------------------------------------------------------------------------------')\n",
    "        trained_models.append(random_search)\n",
    "    return trained_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipe_training(models_params, X, y, n_iter=10):\n",
    "    trained_models=[]\n",
    "    for model, params in models_params.items():\n",
    "        timer = time.time()\n",
    "        random_search = RandomizedSearchCV(Pipeline([('vectorizer', TfidfVectorizer()), ('model', model)]), \n",
    "                                           param_distributions=params, \n",
    "                                           scoring='f1', \n",
    "                                           random_state=24, \n",
    "                                           n_iter=n_iter, \n",
    "                                           cv=3, \n",
    "                                           verbose=True\n",
    "                                          )\n",
    "        random_search.fit(X, y)\n",
    "        timer = time.time() - timer\n",
    "        print(f'Обучение модели {model} заняло {timer:.2f} сек или {(timer / 60):.2f} мин')\n",
    "        print('---------------------------------------------------------------------------------------')\n",
    "        trained_models.append(random_search)\n",
    "    return trained_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_scoring(model, X_test, y_test): # функция для выведения оценки модели.\n",
    "    print()\n",
    "    print('Модель', model.best_estimator_)\n",
    "    print('Лучший f1 при кросс-валидации =', model.best_score_)\n",
    "    predicted = model.predict(X_test)\n",
    "    print(f'f1 на тестовой выборке = {f1_score(y_test, predicted)}')\n",
    "    print()\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим стратифицированные обучающую и тестовую выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data['lemmatized']\n",
    "y = data['toxic']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2 ,stratify=y, random_state=24)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И обучим несколько моделей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Обучение модели LogisticRegression(random_state=24) заняло 54.31 сек или 0.91 мин\n",
      "---------------------------------------------------------------------------------------\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Обучение модели LGBMClassifier(random_state=24) заняло 1068.51 сек или 17.81 мин\n",
      "---------------------------------------------------------------------------------------\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Обучение модели DummyClassifier(strategy='uniform') заняло 32.71 сек или 0.55 мин\n",
      "---------------------------------------------------------------------------------------\n",
      "\n",
      "Модель Pipeline(steps=[('vectorizer', TfidfVectorizer()),\n",
      "                ('model', LogisticRegression(random_state=24))])\n",
      "Лучший f1 при кросс-валидации = 0.7307333387951501\n",
      "f1 на тестовой выборке = 0.7484346224677717\n",
      "\n",
      "\n",
      "Модель Pipeline(steps=[('vectorizer', TfidfVectorizer()),\n",
      "                ('model',\n",
      "                 LGBMClassifier(max_depth=156, n_estimators=132, num_leaves=96,\n",
      "                                random_state=24))])\n",
      "Лучший f1 при кросс-валидации = 0.7793328208875993\n",
      "f1 на тестовой выборке = 0.7814569536423841\n",
      "\n",
      "\n",
      "Модель Pipeline(steps=[('vectorizer', TfidfVectorizer()),\n",
      "                ('model', DummyClassifier(strategy='uniform'))])\n",
      "Лучший f1 при кросс-валидации = 0.1705525046131853\n",
      "f1 на тестовой выборке = 0.1703830760434534\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trained_models = pipe_training(pipe_models_params, X_train, y_train)\n",
    "\n",
    "for model in trained_models:\n",
    "    model_scoring(model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лучший результат на тестовой выборке показала модель LGBMClassifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## spaCy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поскольку как spaCy так и BERT самостоятельно занимаются лемматизацией, то функция `clean_tokenize_lemmatize`, является не совсем подходящей. Поэтому определим функцию, которая делает то же самое что и `clean_tokenize_lemmatize` но без лемматизации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(text:str) -> str:\n",
    "    clean_tokens = []\n",
    "    text = text.lower()\n",
    "    tokens = re.sub(r'[^A-Za-z\\']', ' ', text).split()\n",
    "    clean_string = ' '.join(tokens)\n",
    "    if clean_string == '': clean_string = '0'\n",
    "    return clean_string                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['clean_text'] = data['text'].apply(clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При испытании ядер spaCy для данной задачи лучшим оказалось среднее, так как маленькое давало плохой результат, а большое не давало прироста качества в сравнении со средним."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_nlp = spacy.load('en_core_web_md')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для того, чтобы преобразование текста в векторы проводилось не слишком долго в обучающую выборку возьмем только 30.000 значений. Это слегка отразится на качестве, но зато дело пойдет быстрее."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data['clean_text']\n",
    "y = data['toxic']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=24)\n",
    "X_train_sample, trash, y_train_sample, trash = train_test_split(X_train, y_train ,train_size=30000, stratify=y_train, random_state=24)\n",
    "del trash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bb79296c92e46afab786e02d0f3d707",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train_spacy = pd.DataFrame((spacy_nlp(lemma).vector for lemma in tqdm(X_train_sample.values)), index=y_train_sample.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97fabaf5d8bf4171855fedc0eb416db1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/31915 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_test_spacy = pd.DataFrame((spacy_nlp(lemma).vector for lemma in tqdm(X_test.values)), index=y_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Обучение модели LogisticRegression(random_state=24) заняло 3.59 сек или 0.06 мин\n",
      "---------------------------------------------------------------------------------------\n",
      "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n",
      "Обучение модели LGBMClassifier(random_state=24) заняло 450.61 сек или 7.51 мин\n",
      "---------------------------------------------------------------------------------------\n",
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n",
      "Обучение модели DummyClassifier() заняло 0.49 сек или 0.01 мин\n",
      "---------------------------------------------------------------------------------------\n",
      "\n",
      "Модель LogisticRegression(random_state=24)\n",
      "Лучший f1 при кросс-валидации = 0.6703808655286045\n",
      "f1 на тестовой выборке = 0.6839811115147112\n",
      "\n",
      "\n",
      "Модель LGBMClassifier(max_depth=48, n_estimators=198, num_leaves=35, random_state=24)\n",
      "Лучший f1 при кросс-валидации = 0.708646808953095\n",
      "f1 на тестовой выборке = 0.7184535528906391\n",
      "\n",
      "\n",
      "Модель DummyClassifier(strategy='uniform')\n",
      "Лучший f1 при кросс-валидации = 0.17158780289326295\n",
      "f1 на тестовой выборке = 0.17031046177928513\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trained_models = model_training(models_params, X_train_spacy, y_train_sample, n_iter=30)\n",
    "\n",
    "for model in trained_models:\n",
    "    model_scoring(model, X_test_spacy, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поскольку создание эмбеддингов в BERT занимает безбожно большое время в сравнении с приведенными выше способами, то выборка для которой будет применятся BERT будет довольно скромной (400 значений)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sample, trash, y_train_sample, trash = train_test_split(X_train, y_train ,train_size=400, stratify=y_train, random_state=24)\n",
    "del trash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = transformers.BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "X_train_tokenized = X_train_sample.apply(lambda x: tokenizer.encode(x, add_special_tokens=True, max_length=512, truncation=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если не подать в `tokenizer.encode` параметры `max_length=512` и `truncation=True`, то может возникнуть проблема: *Token indices sequence length is longer than the specified maximum sequence length for this model (1084 > 512). Running this sequence through the model will result in indexing errors*.\n",
    "\n",
    "В теории модель **XLNet** может справиться с более длинными чем 512 векторами. Но мне и так не ясно как эффективно применять BERT (особенно в рамках этого проекта), учитывая, что эмбеддинги производятся так долго. Так что ограничимся BERT."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Применение padding и создание маски:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 512\n",
    "padded = np.array([i + [0]*(max_len - len(i)) for i in X_train_tokenized.values])\n",
    "attention_mask = np.where(padded != 0, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "config = transformers.BertConfig()\n",
    "model = transformers.BertModel.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87761832dd84453ea7d5b18c73375d7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch_size = 100\n",
    "embeddings = []\n",
    "for i in tqdm(range(padded.shape[0] // batch_size)):\n",
    "        batch = torch.LongTensor(padded[batch_size*i:batch_size*(i+1)]) \n",
    "        attention_mask_batch = torch.LongTensor(attention_mask[batch_size*i:batch_size*(i+1)])\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            batch_embeddings = model(batch, attention_mask=attention_mask_batch)\n",
    "        \n",
    "        embeddings.append(batch_embeddings[0][:,0,:].numpy())\n",
    "\n",
    "features = pd.DataFrame(np.concatenate(embeddings), index=y_train_sample.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Обучение модели LogisticRegression(random_state=24) заняло 0.26 сек или 0.00 мин\n",
      "---------------------------------------------------------------------------------------\n",
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n",
      "Обучение модели LGBMClassifier(random_state=24) заняло 36.90 сек или 0.61 мин\n",
      "---------------------------------------------------------------------------------------\n",
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n",
      "Обучение модели DummyClassifier() заняло 0.03 сек или 0.00 мин\n",
      "---------------------------------------------------------------------------------------\n",
      "\n",
      "Модель LogisticRegression(random_state=24)\n",
      "Лучший f1 при кросс-валидации = 0.24074074074074073\n",
      "f1 на тестовой выборке = 0.5625000000000001\n",
      "\n",
      "\n",
      "Модель LGBMClassifier(max_depth=1, n_estimators=158, num_leaves=64, random_state=24)\n",
      "Лучший f1 при кросс-валидации = 0.21666666666666667\n",
      "f1 на тестовой выборке = 0.4999999999999999\n",
      "\n",
      "\n",
      "Модель DummyClassifier(strategy='uniform')\n",
      "Лучший f1 при кросс-валидации = 0.17902711323763953\n",
      "f1 на тестовой выборке = 0.14400000000000002\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train_BERT, X_test_BERT, y_train_BERT, y_test_BERT = train_test_split(features, y_train_sample, test_size=0.5, stratify=y_train_sample, random_state=24)\n",
    "\n",
    "trained_models = model_training(models_params, X_train_BERT, y_train_BERT, n_iter=100)\n",
    "\n",
    "for model in trained_models:\n",
    "    model_scoring(model, X_test_BERT, y_test_BERT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лучшую метрику f1 на тестовой выборке приблизительно равную 0.78 показала модель LGBMClassifier, при генерации признаков с помощью TfidfVectorizer. Можно отметить, что такой способ обеспечивает довольно большую скорость генерации векторов, но в тоже время вызывает взрывной рост количества признаков (каждое новое слово = новый признак, в данном случае размер обучающей выборки составил 127656 строк, 139610 столбцов). Что плохо влияет на скорость обучения модели, поэтому медленно обучающиеся модели вместе с этим способом будут работать плохо.\n",
    "\n",
    "---\n",
    "При генерации векторов через библиотеку spaCy, аналогичные модели показали несколько худший результат на тестовой выборке (приблизительно 0.72 при модели LGBMClassifier). Кроме того для экономии времени модель была обучена лишь на 30.000 значений.\n",
    "\n",
    "Хоть скорость генерации векторов и не так хороша как у TF-IDF, но в конечном итоге получается обучающая выборка с фиксированным количеством столбцов равным 300, что позволяет за приемлимое время обучать медленно обучаемые модели.\n",
    "\n",
    "---\n",
    "\n",
    "Лучший результат при генерации через BERT f1 = 0.56 на тестовой выборке при модели LogisticRegression. Такой низкий результат скорее всего обусловлен тем, что модель была обучена всего лишь на 200 значениях.\n",
    "\n",
    "Быть может если обучить модель на эмбеддингах от полной обучающей выборки и проверить на эмбеддингах от полной тестовой выборки, то её метрика f1 превзошла бы все мои ожидания. Но я этого не узнаю поскольку эмбеддинг всего датафрейма занял бы приблизительно 55 часов на моей машине, а оно мне надо?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "302.391px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
